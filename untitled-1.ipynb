{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.system('pip install snscrape')\n",
    "os.system('pip install pandas')\n",
    "os.system('pip install pymongo')\n",
    "os.system('pip install streamlit')\n",
    "import snscrape\n",
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "import streamlit as st\n",
    "\n",
    "# Function to scrape Twitter data using snscrape library\n",
    "def scrape_twitter_data(keyword, start_date, end_date, limit):\n",
    "    # Initialize an empty list to store scraped data\n",
    "    tweets = []\n",
    "    # Set up the snscrape query\n",
    "    query = f'{keyword} since:{start_date} until:{end_date}'\n",
    "    for tweet in snscrape.TwitterSearchScraper(query).get_items():\n",
    "        if len(tweets) >= limit:\n",
    "            break\n",
    "        tweet_data = {\n",
    "            'date': tweet.date,\n",
    "            'id': tweet.id,\n",
    "            'url': tweet.url,\n",
    "            'content': tweet.content,\n",
    "            'user': tweet.user.username,\n",
    "            'reply_count': tweet.replyCount,\n",
    "            'retweet_count': tweet.retweetCount,\n",
    "            'language': tweet.lang,\n",
    "            'source': tweet.sourceUrl,\n",
    "            'like_count': tweet.likeCount\n",
    "        }\n",
    "        tweets.append(tweet_data)\n",
    "    return tweets\n",
    "\n",
    "# Function to store scraped data into MongoDB\n",
    "def store_data_in_mongodb(data, keyword):\n",
    "    # Connect to MongoDB\n",
    "    client = MongoClient('mongodb+srv://vradmin:vpreCR8304@cluster0.dpqqowe.mongodb.net/test')\n",
    "    db = client['twitter_db']\n",
    "    collection = db[keyword]\n",
    "    # Insert data into MongoDB\n",
    "    collection.insert_many(data)\n",
    "    # Close MongoDB connection\n",
    "    client.close()\n",
    "\n",
    "# Streamlit GUI for user interaction\n",
    "def run_streamlit_app():\n",
    "    st.title('Twitter Scraping')\n",
    "    # Get user input for keyword, date range, and limit\n",
    "    keyword = st.text_input('Enter keyword or hashtag to be searched:')\n",
    "    start_date = st.date_input('Select start date:')\n",
    "    end_date = st.date_input('Select end date:')\n",
    "    limit = st.number_input('Enter limit for tweet count:', min_value=1, max_value=1000, step=1)\n",
    "    # Scrape data on button click\n",
    "    if st.button('Scrape Twitter Data'):\n",
    "        tweets = scrape_twitter_data(keyword, start_date, end_date, limit)\n",
    "        # Display scraped data in a dataframe\n",
    "        if len(tweets) > 0:\n",
    "            df = pd.DataFrame(tweets)\n",
    "            st.dataframe(df)\n",
    "            # Store data in MongoDB on button click\n",
    "            if st.button('Upload Data to MongoDB'):\n",
    "                store_data_in_mongodb(tweets, keyword)\n",
    "                st.success('Data uploaded to MongoDB successfully!')\n",
    "        else:\n",
    "            st.warning('No data found for the given keyword and date range.')\n",
    "\n",
    "# Run the Streamlit app\n",
    "if __name__ == '__main__':\n",
    "    run_streamlit_app()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
